Stateful hacks: http://erickt.github.io/blog/2016/01/28/stateful/
    It can't detect if variables are shared in matches. We can assume they are and count them towards the shared struct's memory usage.
        How will we get the types of them if they aren't actually a variable (like in a match)?
            We can detect if there is a variable with that name.

    https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md

    http://llvm.org/docs/Coroutines.html

    What variance would lifetimes passed to the state struct have?
        We need to know this in order to generate the struct?
        Will they be passed as part of the generic types of fields?
        If so, the type of the return value is affected by the implementation
        We probably should conservatively assume they are invariant here
            Find counterexamples!

        Store the arguments passed to the function in the state struct inside PhantomData!!!
            https://doc.rust-lang.org/std/marker/struct.PhantomData.html

            Why is T: 'a required here?? https://doc.rust-lang.org/std/marker/struct.PhantomData.html#unused-lifetime-parameters

            Actually rust might copy them into an alloca, so we need to include them

        https://doc.rust-lang.org/book/lifetimes.html
        https://doc.rust-lang.org/nomicon/references.html

    How do we preserve destruction order of fields in the state struct?
        https://github.com/rust-lang/rfcs/issues/744

        How will LLVM's closure code work with Rust's generated code with regards to destructors?
            It will probably work fine

    For name resolution and transforming an closure, we're unable to detect variables outside the closures.
        Does this affect the transformation?
            If so we can add an attribute to the upper level so we can detect the variable.


    How can we get the type of a variable?

        How can I assert that the type of a field and a variable should be the same?

        fn assert_type<T>(a: &T, b: &T) {}
        assert_type(&state.field, &var);

    How can we generate intrinsic with LLVM types handle and i1?

    We need to add space for futures in await!() since those live across states!

    How does it interact with MSVC and GCC style exceptions?

    Have a Coroutine trait, then implement Future and Iterator for all types T: Coroutine

    How do teal with LLVM's token type?
    Can we modify LLVM to remove it?
    Can we add native token type to Rust?
        Possibly if local variables do not use alloca if there are no refernces to them in debug mode

    Can Rust's trans introduce allocas on top of local variables which can live across state points?
    Can LLVM introduce more state to be put in the state struct with is not allocas?
    Say a %val = ...; and val is shared between statepoints

    LLVM 4 upgrade https://github.com/rust-lang/rust/issues/37609

    LLVM's coroutine CoroElide's pass will inline a coroutine without the split and remove the coroutine instrinsics making optimization easier
        Can we do something like this for frontend state transformations?

    https://github.com/llvm-mirror/llvm/tree/master/lib/Transforms/Coroutines

    In a LLVM function without alloca, what is the possible states?
        phis and function arguments?
            Can we relate the state size of phis generated to number of allocas?
                Is the storage bounded by the largest phi in the function?

        a load before a suspend point would also need to be stored

    If a LLVM IR function has no phis, the size of it's coroutine frame is below or equal the size of it's parameters and all allocas.
    We must have an invariant on LLVM optimizations, that the size of a coroutine frame is below or equal that of the function before the optimizations are done.
    We must require that LLVM optimizations never increases the size of a coroutine frame.
        This doesn't work if LLVM inlines things.
            How does that work for frontend transformations?
                ^ this is similar to inlining ^ We need to add space for futures in await!() since those live across states!

    C++ coroutines
        https://isocpp.org/files/papers/N4402.pdf
        https://paoloseverini.wordpress.com/2015/03/06/stackless-coroutines-with-vs2015/
        https://www.youtube.com/watch?v=8C8NnE1Dg4A
        https://raw.githubusercontent.com/boostcon/cppnow_presentations_2015/master/files/CppNow2015_Coroutines_in_C%2B%2B17.pdf

    For a Rust RFC, detect coroutines by the use of their keywords

    How does Rust deal with mutually recursive functions both returning impl Trait?

    Future's Poll enum is wrong. A future should only have 1 result (possibly Result<>). So a future should return an Option<T>. None if it's not ready. Some() if it is.

    Does FnOnce FnMut and Fn variants make send for Coroutine?
        self would make you unable to run it multiple times, so no.
        &self would make it unable to change states, so no.
        &mut self is the only option left

    How can we pass on the argument to await!()?

https://internals.rust-lang.org/t/pre-rfc-coroutines/4281
https://github.com/rust-lang/rfcs/issues/388

https://github.com/rust-lang/rfcs/pull/53


Hm.. I tried writing out coroutine traits, but I can't actually implement them for futures. I want to do for all coroutines implement Future and for all futures implement Awaitable, which isn't possible due to trait coherence rules
    Can we require rustc to pick the same implementation of all Awaitable used in await in a function?
        How do we expose this to implementations of Awaitable?

    For Yield. We need to ensure that they never happen. Can we require Yield = ! ?

    Avoiding yields with the wrong values in futures will require separate Yield and Await results?


When should we cause a coroutine to be generated?
    In the case with no yield! or await!, can we use a return! to force a coroutine?

Python optimizations
    https://www.python.org/dev/peps/pep-0380/#optimisations

Should we separate the `Coroutine` into two traits, one for futures and one for generators?
    Avoids the need to have the Coroutine trait in libcore!
    Infer which is needed based on yield! and await!

    Call the await one Task

    https://github.com/dotnet/roslyn/issues/261

    Look at F# https://github.com/dotnet/roslyn/issues/261#issuecomment-95269316

    It would seem both are useful? How does this work
    http://tomasp.net/blog/async-sequences.aspx/

    Both yield! and await! is a Stream right?

    How does a for loop over Stream elements look?

    for Future<item> in stream.iter() {

    }

    let val = await stream;

    if val == none exit;
    yield 


    WaitFor/await would consume the input? so it doesn't make sense for Stream. Would it make sense for &mut Stream?

    WaitForAll for Streams?
    Can IntoStream trait like IntoIterator?

    How can you yield all values from a Stream if yoou are implementing a Stream?


        ForAwait will need some trait like WaitFor?

        Some await for construct?

        await(v) maps to

            let mut future = IntoFuture::into_future(v);
            loop {
            loop {
                if executor.wait_for(&mut future) == NotReady
                    await;
                else
                    break val;
            }


        http://xion.io/post/code/rust-for-loop.html

            for await x in v {
                // body
            }
        Maps to
            let mut stream = IntoStream::into_iter(v);
            loop {
                let next = loop {
                    if executor.wait_for(&mut stream) == NotReady
                        await;
                    else
                        break val;
                }


                match iter.next() {
                    Some(x) => {
                        // body
                    },
                    None => break,
                }
            }

        Like how this 
            for x in v {
                // body
            }
        maps to 
            let mut iter = IntoIterator::into_iter(v);
            loop {
                match iter.next() {
                    Some(x) => {
                        // body
                    },
                    None => break,
                }
            }

IMPORTANT: How can we deal with borrows of locals across suspend points?
    Stateful deals with those by construction
    I guess this is why C++ does heap allocations?

    Can we repply/recalculate borrows after a suspension point?
     I don't see a counterexample to ban this

     One counterexample is unsafe abstractions

     Can we do a state machine transformation in MIR before borrow checking?
        How would that help? Examples!!

Add errors and use ! in our traits!
    How does errors interact with Streams and for await loops?

Should Await<Future> take the future by ownership?
    Or should that only be on the `await` layer. So an await statement take a future by move!

Implement await! and await_for! with macros and only add native suspend statement?

Do type inference -> borrowck -> state machine transform -> borrowck
    The 2nd borrowck verifies the implementation of the state machine transform
    We must restrict lifetimes during type inference.
        Lifetimes passed to the coroutine are always legal.


    PLAN: No not change lifetime inference at all, but change borrowck so that it gives errors for lifetimes crossing suspend points

    The state machine transform should run after borrowck to ensure good error messages!

    How can we deal with references extending to the end of a scope?
        Say
            let r = &5;
            await make_future(r)
            // implicit drop of r
        Here r is illegal

        Look at this example in Stateful

        Can we have more narrow scopes for types without destructors?

    We cannot allow lifetimes which start in one statepoint and ends in another.
        Or lifetimes of references (or anything taking a lifetime parameter)

How does ? compose with await await-for and everything above in general?
    For futures ? is no problem. It would just make them return Err() which is what you normally expect

    For generators, ? is allowed when Result is generated. Does this has the same problem as below. Should an Err terminate the Iterator?
        Rust has no concept of an Iterator returning errors! We could provide an analougus one. Also we can have a Stream trait which doesn't produce errors like Iterator

    For streams, ? should be able to end a stream with an error. However streams return ()!. So streams should return Option<Error>. None when no error happened, Some()

A prefix ? operator would match better here?
        let val = ?await future;
    vs.
        let val = (await future)?;

Can we use Await for Streams by having a special Future wrapper which can keep references to the coroutine frame?
    Would require a trait to convert streams to futures anyway?

Can we create some abstraction which lets us keep references to stack frames?
    By say, storing them relative to the coroutine frame. It should lend out real reference which again can't cross.

Store pointers to locals used in await/for await as a value relative to the coroutine frame, so they don't become invalid
    The references aren't actually used across state points though. We can assign the object to a local and create a new reference for each loop iteration

Have an error result for the for await loop?
    for await connection in socket {
        ...
    } else error {
        panic!("Got an error {}", error)
    }

Can the for loop return the result? So if you aren't interested in the error
    for await connection in socket {
        ...
    }?

So a `for await` returns Result<T, Self::Error>. If T is unconstrained, it defaults to ()

Should `break v` in a `for await` 

How to avoid errors when Self::Error = !?
    Can this just be a change to the Result warnings?

Coroutines without a yield statement have Yield = !

Should we require a keyword for the coroutine transformation so regular functions without yield/await can become coroutines too.
    <tomaka> one specific problem I can think about is if I write   `let foo = || { yield 5; 12 }`
    <tomaka> and then you decide to comment out `yield 5` just to try something
    <tomaka> and suddenly your closure is no longer a coroutine and compilation breaks

<tomaka> Also coroutines would probably need to implement Clone
<tomaka> because if you write `start_http_server(handler: C) where C: Coroutine` you need to start a fresh coroutine once for each request received


In this example:
    for await request in server { spawn(handle_request(request)) }

    How does the coroutine access the spawn function? It should be a method on the event loop.
    Does this justify a `spawn task` statement?

    We could just have a suspend expression (which returns the event loop). How do we then access the event loop before the first suspension point?

Have a coro expression which returns a coroutine struct.
    let server = coro {
        yield a;
    }

    This is just regular closures though!

Can we write computations that are generic over sync/async? They would be generic over the executor?
    Which will completely undo the state machine transformation?

    fn count_to_10<E>() -> impl Stream<E> {
        for i in 1...10 {
            await sleep(1000);
            yield i;
        }
    }

    Pass AsyncEventLoop for E

    Make Async generic is such a way that only Ready() is possible? If that is required to make efficient sync code
        Make NotReady have generic type. Set it to () for async. ! for sync

        Would this make code generation simpler?

        Can we make Coroutine generic in a similar way, so Awaitting also returns a generic value?
            Yes!
            No - limit this madness to Future and Stream only, if possible

    Make a trait Executor with E: Executor in Future and Stream

    fn computa

    spawn correspond to spawning a new thread for sync

    Can we make a more basic trait which only returns 1 value from suspend points?
        implementations can require a more complete result?
        Would work for await,
        yield can't infer such yield type?
            This is true, not for Iterator, but for Stream.

            Having the yield type be a function of the executor would require higher kinded types

        We can use this to get rid of Awaitting then!

        Just Yield and Return would do here!
            Check this for streams
                Just have Stream give another yield type?

See if ATC or HKT can move the Blocked case into Future/Stream 
    https://internals.rust-lang.org/t/blog-post-series-alternative-type-constructors-and-hkt/4300

    This would allow:
        <Zoxc> So you could yield different types and they all would give the same type as output

        How would that actually be used though? impl Stream<IntoExecutor<E, Str>>? Tries to convert values into Str when yielding

        Would this prevent type inference?

        Would it require a custom Executor for Stream?

        Can you compose coroutines with different executors?

!!!
Let Await Be Future and AwaitElement Be Stream. Can we implement an event loop executor?
    Can we derive futures-rs traits from these? (for its executor)


Can trait Future: core::Future<FutureRsExecutor> make sense?

Drop the above, we got things working!

We need a Spawn trait for executors?
    trait ConcurrentExecutor: Executor {
        type Task;

        fn spawn(task: Task);
    }

    Task will be unsized here. Can we defer to upper level event loops to implement Spawn? Yeah


Will we need some extensions to Executor to be able to added real futures like RPC?
    Probably will need an Executor extension per event loop type

How many Executor implementations do we need?
    One for sync, which is ()
    Compare to how futures-rs need no executor type parameter, but still allows multiple executors
    Could we have just one for async, like futures-rs?
        If so, passing a bool as a type parameter count indicate sync/async

        impl Future<true> // async

        Could also just be an enum with Sync/Async

Can we implement the unsafe Future extension?

Check if we can infer E for hm() if hm() is called in another coroutine and E: ExecutorExtension for both

Can we still have a suspend operation which returns State and use that to implement await/await_for on top?
    Yes
    We can't use macros, as await will add new bounds to the executor for the coroutine

    Translate await/for await/yield to suspend in HIR 

Leave calling a coroutine after it has returned as undefined? Like Iterator and Futures do? Still memory safe and allows optimization

For coroutine implement require A1, A2, .., AN E: Executor + Await<A1> + Await<A2> +  ... + Await<AN> so we can actually await on things.
    Will this compose?

    Would require that the caller's executor should be able wait on the same types?
        If we infer Coroutine<Ref<..>> then we should be able to prove the Await bounds too?

How can we infer the return type of a Coroutine. It depends on type inference of the resume function!!
    The type of an argument to Await also depends on type information!!

When are closures expanded to function/struct/impl?
    We probably need to delay some of this to post-MIR for coroutines

Add suspend points to the list
    The kinds of expressions which in-scope loans can render illegal are:
        any suspend points
    Here https://github.com/rust-lang/rust/tree/master/src/librustc_borrowck/borrowck

    Check that the lifetime of each loan (after borrowck gathers them) doesn't contain any suspend expressions
        Ignore loans of data with a lifetime greater than the function

        What about a custom pointer type Ptr<'a> returning &'a ptr.
            It would have to be passed to the function, so 'a must outlive it!

    Add a new RESTRICTION ACTION, TEMPORAL which means that a loan cannot cross a suspend point

    We need to track the source of borrows? Use a dataflow analysis here

        We flag a variable when we assign a borrow to a local variable.

            fn test(a: &T) {
                let v;
                let mut f = a;

                suspend; // Is `f` to external data here? Should be yes

                loop {
                    suspend; // Is `f` to external data here? Must be no

                    if true {
                        f = &v;
                    } else {
                        f = a;
                    }
                }
            }

        Make sure we handle cases where lifetimes are explicitly used to pass to data.
            It won't be an error to treat these as local?

        Later on we enumerate all suspends points and check if any variables are flagged there. If they are, ensure that the lifetime of the variable doesn't intersect with the suspend point.

        We can enumerate borrows and compute if they can be flagged. If they can be, ensure that no suspend points are in it's lifetime.

        Compare it's effect with how a state transform would change lifetimes?

        Let's transform the above example:

            fn test(a: &T) {
            S1:
                let v;
                let mut f = a;
                goto S2(v, f);
            S2(v, f):
                // Is `f` to external data here? Should be yes
                goto S3(v, f);

                loop {
            S3(v, f):
                // Is `f` to external data here? Must be no
                goto S4(v, f);
            S4(v, f):
                if true {
                    f = &v;
                } else {
                    f = a;
                }
                goto S3(v, f);
            }

        Can we do a mock-transformation in borrowck identify crossing variables? Would this always be the same as the flagging dataflow analysis above?

        This is just liveness analysis and comparing the lifetimes of variables with the suspend points.
            Would we have to compute this before borrowck anyway to generate the state struct?
            Can we use this information to find

        An alternative would be to transform before borrowck, but we need to translate error messages from borrowck back

        Simplest solution would be to either identify crossing variables in MIR or to actually translate it 

        When does Rust need the size/layout of the state struct?

        What would happen to mutually recursive functions?
            fn a() -> impl Coroutine<()> { b() }
            fn b() -> impl Coroutine<()> { a() }
        Would they require the result of each other?

        Look at the transform done in https://github.com/erickt/stateful
            Done at the MIR level, so trivial.

        Can we have borrows which cross suspends points without variables?
        (&mut local_var)(suspend)?
            Yes!

        We also need to catch variable state crated with alloca! and prevent it from crossing state points
            Just banning alloca! in generators would suffice. Users can refactor it into regular functions!

        http://manishearth.github.io/rust-internals-docs/rustc/ty/enum.Region.html

        Check how to deal with borrows of captured variables in closures

Check how MIR deals with lifetimes https://blog.rust-lang.org/2016/04/19/MIR.html


PROBLEM!!!
<Zoxc> I think we'll be unable to write the impl of ReturnTest before typechecking
    Actually we only depend on the type information of the resume function. We can type the wrapper function later!
    But type checking does depend on that impl

    Probably some nasty interactions with closures inside

    CHECK!!! that Await doesn't result in some similar problem

    THIS INTERACTs with bounds. We need to inherit the bounds from the resume function!
        Still fine. We only provide the impl after typechecking!
            Not actually true. The impl provides guidance to type inference

            Do this?
                1. infer the body of the function. Let the executor and the return type be fresh type variables there.
                2. replace the body with a struct value
                3. claim that the struct implement Generator (without any trait bounds on it)
                4. infer the function again, expecting it to resolve the trait bounds we ignored earlier

                How can this infer ExecutorRef?

                Does this run into the same problem as we did with a syntax expansion? 
                No
                Example

                    struct ReturnTest<F> {
                        next: F,
                    }

                    impl<E: Executor, F> Coroutine<E> for ReturnTest<F> {
                        type Return = usize;
                        fn resume(&mut self, executor: E) -> State<Self::Return, E::Blocked> {
                            panic!()
                        }
                    }

                    fn id<T: for<'e> Fn(Ref<'e, E>) -> R, E, R>(x: ReturnTest<T>) -> ReturnTest<T> { x }

                    fn return_test<E: Executor, A>(a: A) -> impl Future<E> {
                        ReturnTest {
                            next: a
                        }
                    }

                Explore how this affects closures!!!!!
                    Look at closures which return impl Future


Should Streams either Yield(Value) or Return(Result<Err, Ok>)
    So a for awit loop would abort when the Result comes in?

Can typechecking depend on MIR being generated for the function? This would be very useful

Executor::Blocked could be given an event the task should block upon, instead of registering it with the event loop.
Probably less efficient though

Can we have a macro await! if we add syntax to get the argument?
    We need to add the relevant trait bound to the function. (which in turn adds it to the trait)
        Would just calling a function give the same bound?
        Will we need to add other bounds from the function to the trait impl too? This might be the only case?
        See what closures do?

        It seems like we need to add all bounds from the function onto the trait impl

Can we use intrinsics for suspend and to get the arguments?

Can we let generators wait on other generators directly, say given the same Executor?
    No, we wouldn't be able to wait on real future objects that aren't generators

Build a more basic abstraction using suspend and get_executor intrinsics and a function trait?
Can we use intrinsics for suspend and to get the arguments?
    We can use intrinsics like get_executor<E>() and let it guide the typechecker

    The problem is that return is above this level of abstraction, so we need support for generators in the language anyway

Can we have a `for await var in ..` loop? Does `await var` conflict with patterns?

Explore how composing futures work with regards to the Executor type parameter and further bounds on it which can allow real I/O interactions 


Combine Await and AwaitGenerator!
    We have to combine Future and Stream then!

    type Future = Stream<Yield = !>? // No these are traits!

    Can ||Does a `IntoGenerator` trait, analogus to IntoIterator for `for`-loops make sense?|| help?

        pub trait IntoGenerator<E: Executor> {
            type Yield;
            type Return;
            type IntoGen: Generator<E, Yield=Self::Yield, Return=Self::Return>;
            fn into_gen(self) -> Self::IntoGen;
        }

        impl<G: Generator<E>, E: Executor> IntoGenerator<E> for G {
            type Yield = G::Yield;
            type Return = G::Return;
            type IntoGen = G;

            fn into_gen(self) -> Self::IntoGen {
                self
            }
        }

        Trait coherence doesn't allow this!


Let generators have the ability to wait on other generators?
    Wouldn't work with Futures.
    We can implement generators for futures, but that might be bad and or confusing?

Can we have a global function sleep() which can be used for multiple downstream Future traits?
    
    Yes, say:   
        Hm... we need Await<Sleep> here!! // We don't if we manually implement it!
        fn sleep<E: SleepExecutor>() -> impl Generator<E, Yield = !, Return = ()> {
            await executor.sleep(); // No access to executor here. Must manually implement this.
        }

    Can downstream traits just be
        trait Future: Generator ....

CHECK: Closures which have references to local state being returned as a generator from the parent function.

a(1, suspend, 2) is an example of where temporary variables live across state points

C++ design
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0158r0.html

A yield in a macro could result in confusing errors. A case for adding a coro keyword?

Consider implementing an inlining optimization specifically to combine generators.

Ensure destructor order is correct when panicking.

Could you access generator arguments using a wrapper object and await on it?
    Yes - add an example for this!

    Would this be useful to call methods on the executor too?

<Zoxc> vadimcn: Do you have a use case where you have to pass arguments to each resumption of a coroutine?
<vadimcn> Zoxc: yes - a double-ended iterator, for example
<vadimcn> another example would be an incremental parser into which data is "pushed"

<Zoxc> vadimcn: Any ideas on how to reduce the syntactic overhead of that in cases of no arguments? or on how we would a coro keyword to closures?
<vadimcn> Zoxc: something like #[gen] attribute?   Although, IMO it isn't necessary.  Nobody complains about returning closures when something callable needs to be returned, and this brand of coroutines is quite close to closures.

Can we add Arg as another input to generators, which will default to () if unused?

Use a syntax like coro(arg1: &str, arg2: &str) fn a() {}?
Or coro fn a()(arg1: &str, arg2: &str)?
Can we use a keyword inside the argument list to pass coroutine arguments and indicate that this is a coroutine?
    Would also work with the closure syntax

    Ideas for that? Can we use x y here too? so |coro a: int| or |coro| <- conflict! No

    Keywords https://github.com/rust-lang/rust/blob/master/src/libsyntax/symbol.rs#L164

Cannot have coro fn, since coro is not a keyword (would conflict with expressions) require fn coro
Would the arguments magically change after a suspend point?

Bad things with https://github.com/rust-lang/rfcs/pull/1823
    Coroutine return types are not associative types? Is that true? Probably not.
    Requiring closures in order to return generators
    yield can't be nice for async

Does generators need to take &mut self?
    The state point could be an Cell<index>

    It does have visible side effects

    Should this match Fn for function and Fn* for closures?

Instead of passing arguments in, have a function which extracts them? May want syntax here
    Access the argument with a `self`-like keyword
    How to access the executor then?

    Is ref free in expressions?

    Use `ref arg` or `ref exeuctor`?

    Keywords: https://github.com/rust-lang/rust/blob/master/src/libsyntax/symbol.rs#L164

    Can we give warnings if coroutine arguments are unused, even if it isn't Result?

    Problematic case with ref arg:
        let mut r = ref arg;

        if true {
            yield
        }

        r = ref arg; // Illegal!

        Not a problem with await since it borrows

        Can this be integrated with borrowck dataflow?

        Does this apply to normal variables? Yes!

            let mut arg = String::new();

            let mut  r = arg;

            if true {
                arg = String::new(); // Validate arg 
            }

            r = arg; // Illegal!

        `ref arg` acts like an argument/variable except it's overwritten every suspend point.

    Add ref executor too

    Can we have `ref args` be sugar that extracts arguments from an executor wrapper?


    We can use a closures like vadimcn's proposal only if we require arguments?

Is there a reason for futures/streams to receive an argument?
    Maybe pass down the reason for the resumtion of a task?
        Or that could be stored in the executor?

Should we wait for associated type constructors, so we can move await, await for to a higher level? What would that look like?
    Can we move the executor to a higher level too? What was the problem there? INVESTIGATE, might result in a clearer async design on top

Should you be able to Clone coroutines?

Hm... so I can use `await for` and have await be a contextual keyword :D

Add Arg as a type parameter to Generator
    await might want to pass on both the argument and the executor!
        Could it wrap it's argument in the executor then? Probably

    Can we have Arg be an associated type? Why is it not for closures?
        Would allow one object to implement multiple function calls with different arguments?
            Is this useful?

        <eddyb> Zoxc: because arguments are inputs
        <Zoxc> eddyb: What do you mean by inputs?
        <eddyb> Zoxc: I mean, if nothing else, lifetimes
        <eddyb> Zoxc: for<'a> Trait<Assoc = &'a T> is wrong and banned
        <eddyb> it has to be in an input position for it to be a lifetime input
        <eddyb> Zoxc: ok so assuming you only care about lifetimes: associated types are *fully* determined by Self and arguments
        <eddyb> Zoxc: aka trait inputs
        <eddyb> Zoxc: so for<'a> has to be used in the trait inputs otherwise it can't appear in outputs
        <eddyb> Zoxc: so with just associated items you can't represent Fn(&T) or Fn(&T) -> &U

Can we have the executor be an associated type and still infer everything we'd like? How can we connect it up to type parameters on the generator fn<E: Executor> -> impl Generator // no <E>..
    No

Impl Await for suitable generators, so designs where generators == futures are possible

Can we pass argument per resume to streams only for resuming from yields?
    Does the passing arguments to parsers or iterator examples still apply?

It doesn't make sense to pass resume arguments to futures for events, since they also would be passed when resuming streams after yields

Can we introduce some magic for yield so await can be built on top?

Hm.. would a remote double ended iterator make sense? https://github.com/vadimcn/rfcs/blob/coroutines2/text/0000-coroutines.md#double-ended-iterators

Is the incremental parser example useful with providing arguments or is await better there?

Pass the exeuctor by ownership so we can use a 0-sized type there (say PhathomData<&mut E>). Also allows optimization of arguments passed in
    Passing by ownership doesn't work with Await? any solution there? Will we require inlining for optimization then anyway?
        We can probably force inlining on the Await impl

        LLVM can remove the unused argument if the function is local (which is likely)

        Is there a way to have &mut which is 0-sized if its target type is?

Can we guarantee the return of data on Blocked()? No - select() requires that we discard all but one Blocked() results 

Can we optimize the state machine data layout if everything gets inline and we can prove that no addresses are taken?
Can we always optimize annoynmous structs?

Let the Task be passed as the executor argument instead of an EventLoop, let the Task hold a reference to the event loop.
    Cleaner design? but more memory usage, use it for the example only?

In our EventLoop timer function, can we ensure that a task is active? Does the above design achieve that?

Unable to implement SleepExecutor for FutureExecutor. Must we require that Await traits are implemented in the Future library to fix this?
    Or require that a Future is a Generator

    Or move my Future and Stream definitions into libcore <- best option? Can futures-rs just implement them for their futures?
        Test this!

        Move &mut into the trait so chained FutureExecutor doesn't have overhead

Major problem, if we implement Future for all generators, we cannot define further future implementations
    Can we use some wrapper magic here? Must we expose this to the user?

Can do we run into trait coherence problems with futures-rs too? Probably

Use a Handle to the EventLoop struct. How to avoid an extra indirection here?
    We kind of want 2 interfaces to the same type here!

    Use unsafe code to cast an EventLoop to an Handle and back? Make Handle unsized.

Use IntoGenerator for `await` and `await for`? https://docs.rs/futures/0.1/futures/future/trait.IntoFuture.html

Panicking after returns is more efficient. We don't have to check for errors in the callee.

Can we let the argument to pass be a associated type of the Executor?
    say type Handle; doesn't seem to help with the borrowing..

What happens if we drop a timer in our example?
    Can we test if the ref count is 1?

Add a spawn method to our executor examples?

ArgsExecutor means creating wrappers for SleepExecutor, etc. not very ergonomic

How to deal with lifetimes in arguments? Must we add them to the impl result?
    If we don't require that, we must add the bounds that they outlive the state struct

    We have to act as if they are stored in the state struct. We need non-lexical lifetimes if we want their lifetime to be shorter.

TODO:
    Check if we can have IntoGenerator and implement that for downstream Futures or awaitable objects like RPCs?
        Looks a lot like our Await trait, same trait coherence problems? It has the type parameters reversed, so maybe not
    Add a spawn function to our executor example?
    Provide an alternative `await` syntax
    Keep Await and AwaitGenerator so future changes to trait coherence rules would allow futures-rs to support it?
    Just have blanket impls for Generators for now?
        Would this just be IntoGenerator? Kinda. Should we pick IntoGenerator or Await then?

Need a way to access the executor in HIR!


<Zoxc> Is changing `for` to take IntoIterator instead of Iterator backwards compatible?

Suspend would be a terminator in MIR with two paths like call, the unwind path gives the actions to take if the generator is dropped during the call

What would inlinig of a generator (pre-transform) into another look like?
    Look at LLVM!

    Inlining await seems simple. Inlining yield is more tricky? Look at LLVM for these 2 cases

    Does it only make sense to combine generators if their suspend type match? Also possible to ignore ! when matching. So futures and iterators can both be merged into a stream
        Can we do this optimization if we only have Yield and Return, no Blocked?

        Can we only inline await expressions?
            Do we need await on the MIR level for this?

            This is just normal function inlining pre-transformation? Or is it, look at the loop on the caller side
                How can we detect if it's illegal (other than just await inside)

    Can we have some more general state machine optimization?

    We can inline iterators and streams, but only if we have some yield_from / yield_await_from construct?

    Syntax yield.., this just suspends when the caller does, until it hits Return.
        Is this equal to await when Yield=!? It seems so!

        What is the return value there? The return of the generatored yield..'ed, Yes.

            yield.. passes in the arguments from the caller to callee!

            We can use it to access the argument like my await trick

    Can we extend this optimization to leaf RPC futures? Doesn't seem to make sense

    How can yield.. pass on the executor for await? Let it be able to pass a single value on each yield?
        How does borrows work with this?

<Zoxc> nmatsakis: Hm.. what about running the transformation right after MIR generation, then run borrowck. Then we revert to the pre-transformation MIR and run optimizations and use that for further passes
<Zoxc> nmatsakis: I think that makes a lot of sense since there are cases were we only do the transformation to run borrowck.
<Zoxc> nmatsakis: Say if the yield type is !, we must do the transformation just for borrowck
<Zoxc> Hm.. we don't actually want to transform until monomorphization in that case
<Zoxc> If we know the yield type is !, we could just run borrowck pre-transform and ignore suspends
<Zoxc> So I guess we'd want two kinds of transformations, one where all suspend operations are replaced with unreachable statements
<Zoxc> Each function would have 2 MIR outputs, and we'd pick the one to use for LLVM IR generation

Hm... in the above case we could allow borrowck to ignore suspends?

monomorphization

Have some syntax on `fns` for generators and reserve await inside there only!!!
    Can we deal with `await` identifers in macros, does hygiene save us here?

    Can we have a postfix syntax let a = read() =>?; which composes better with?

    Wouldn't be able to make macros that use await.. :/


Note that the Drop impl will require a 3rd MIR body

Have Args be an associated type of Executor and use it for both arguments and the executor handle
    Can we have await require that the handle is &mut T for some T?

    Can we implement a Handle<'h>(&'h mut EventLoop)?

    Require Deref on it for Await?
    Hm.. we need a reborrow function which produces another Handle? Can this work?

To Poll() the to get into the yield position, can we use some type level state machine and an impl Consumer trait which does the poll() for us?
    Can we have an "constructor" for the Consumer trait which turns object of another trait into it?

    Like have the provide() method call resume(None), then resume(Some(input)) the first time?

    So the argument value to a generator would be Option<T>, but yield returns T! So yield is an operation on top of suspend here. We can define the Consumer trait and yield! macro on top.

    Can we tie the yield! macro to the Consumer trait implementation for Generators somehow to avoid the panic overhead?

The same trait coherence problem applies to `yield from` for Iterators as it did for Futures. We want to use a IntoGenerator trait here, but can't actually implement it. We want to be able to yield from existing iterators and futures. The solution of having futures just be generators won't work for iterators.

If we do borrowck after a transformation of MIR using liveness analysis, we could end up with "illegal" programs,
    like
        let x = &mut 4;
        yield;
    it would pass that, but not a normal borrowck pre-transformation
    can this result in problems?

    x isn't alive across the suspend point here

    Can we use a transformation which lifts all variables/temporaries into the state struct?

    We would like to use the lifetimes computed by MIR borrowck in other to do this transformation so no "illegal" programs would be allowed. This would require borrowck to run before the transformation!

Look at async/await in C# (and the Midori os project)
    http://joeduffyblog.com/2015/11/03/blogging-about-midori/

http://joeduffyblog.com/2015/11/19/asynchronous-everything/

For RPC, do we have to store both the arguments (since we must wait until poll too create it) and the result? 
    Maybe I'm wrong here. Look at what tokio /cpupool does

    The timer example will need to be fixed then....

For the trait coherence problems can we have fn() => yield FutureWrapper which wraps the body in a Future struct?
The FutureWrapper struct implement Future if the contained item implements Generator.
IntoGenerator just returns the inner body there
Can the FutureWrapper struct have bounds on the generator inside which gets applied

If the return type is plain impl Trait and that Trait has an attribute with indicates a wrapper struct, wrap the return value of the function in that struct. struct IteratorWrapper<T>(T) should implement Iterator if T does.
    Maybe do this only when the function is marked as a generator?

We kind of want a function from traits to wrapper structs here. So we can return impl Future.

We can implement IntoGenerator for all Iterator and specialize for IteratorWrapper

<nmatsakis> Zoxc: seems like a problem :) some of the techniques I descirbed in my blog posts about improving specialization would be applicable, but otherwise I suspect a newtype would be needed (e.g., `struct GeneratorIterator<G>`, which impl Iterator for all G: Generator)

Extracting the arguemnt with yield.. might run into borrowck issues since it has a suspend point
    You could move the extraction to the top or the previous suspend point to avoid these issues

Look at asyncio in python

Can we let await! just wrap the future in a YieldFuture() struct?

How can reborrow the exeuctor like await in yield.. ?

Do we need 3 variants of yield from? yield.., yield mut.., yield ref mut..
    Or will type inference help us?
        I think type inference helps here


http://smallcultfollowing.com/babysteps/blog/2016/09/24/intersection-impls/
http://smallcultfollowing.com/babysteps/blog/2016/10/24/supporting-blanket-impls-in-specialization/

Make sure a future combinator in another crate which is generic over executors work

Can you implement try! with coroutines?
    https://channel9.msdn.com/Shows/C9-GoingNative/GoingNative-39-await-co-routines
    ^^ example

Add conditional initial suspend like C++?
    Use an associated constant?
    How do we tie it up to the generator type?

    It would be somelike like RealReturnType: Generator?

    Can we have somethinglike trait GeneratorInfo, and implement it for Futures, etc.?

    We can bring back our Executor type parameter/trait, and call it Abstraction instead.
    Abstraction gives us information about how generators should work.
        We could also possibly wrap the returned generator in the concrete Abstraction type?
            Could help with specialization?

        Hm.. a initial suspend point wou

        Can we have Args be an associated type of Abstraction?

        We kinda want ATC here for yield and return type
        How will `await`/`yield from` and `await for` work here?

    Does futures-rs allow generators without initial suspend?
        Must this match the behavior of native functions returning futures?
            That probably makes sense

        This means the event loop might not be running when we create a future!
            tokio passed the event loop explicitly to get around this

        What should we do with the return values then? Say we yield something in the first call?
            For futures, we store the return value in the futures itself.
            For streams, can we store one element of the stream inline?
                Would implementation of streams buffer such elements anyway?
                    Such buffers might be part of a lower abstraction?
                        We won't get a return value out from lower abstractions! since we just get a Stream

        Are will streams require poll() first like generators?

        Can we optimize out our "Tasks" which needs to be poll()'ed to start on the lowest levels?
            Can we write the low level code (RPC, sleep, etc.) using generators to manage state?

    Does having futures require poll() first run into problems with borrows.
        Say https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html
        We'd capture the &str there, and it cannot live across a suspend point!
            I can't think of a problematic case
            But this is less flexible. We'd have to await on it immediately!

        Futures has to live across suspend points so letting them hold references to locals isn't possible.

        Can we have await() poll the future once which returns another future which is 'static? 
            So IntoGenerator/Await would return a Generator which is 'static?

            Let resume() take the future by ownership and return another which is "compatible", but 'static
                Probably best to have another prime() function call

                Could possibly have multiple prime() stages at the type level, so and each stage can lose a lifetime variable bound? Probably can't express that at the type level, and doesn't play well with await being a loop

                We need to detect variables alive at the first suspend point?

                How can we detect the point to prime a generator at?
                    Does it makes sense to prime after a suspend point?
                        Probably not for await atleast

                    What will we do if we have the first suspend point in a loop?
                        Do the first iteration of it?

                Hm.. we need a primed generator which isn't 'static, but have just less type variable bounds.
                    How can we manage this?
                        Probably need a bound on the primed type in the function?
                        Can we express that the primed type "outlives" the non-primed one? So lifetime bounds can't increase?

                Can we have a PrimeGenerator trait which is only implemented for generators where priming has an effect.
                await will specialize it's implementation based on wether PrimeGenerator is implemented or not.
                    Join future combinators will need something more flexible?

                    Join<A,B>::HasPrime = A::HasPrime || B::HasPrime;

                    Can we have such a constant? We require the value of it during type checking in order to decide if we are going to prime a future or not.
                        Would we have to specify it in the return impl Trait of functions?
                            Probably

                        Can we somehow pick resume() over prime() later on without resulting in unsafety?
                        Can we share the representation of the Generator and the primed generator so resume() and prime() work on the same representation?
                            They probably only need to share storage location of arguments and the state?

                            Can we apply this trick to the inlined loop too?
                                Only if the future is actually a generator..
                                We won't know until monomorphization
                                    We'd like to inline things before then

                                    Could we inline the future before then before? We'd also need to know if it was a generator
                                    If we know it is a generator, we can apply this optimization

                                    Should we inline even if we don't know if it is a generator?
                                        If we can inline, we know if it's a generator or not, we always want to inline

                                Like we don't call prime(), but just resume() we we know will be valid.

                Can we have "priming" be some type system feature?
                    So calling resume() removes lifetime bounds on Self?

                We could have Gen::Prime be non-movable. This would allow us to have futures that don't move during await?

                    Think non-movable generators.
                        let result = something();
                        await result;

                        Here result can't be non-movable since it actually moves.
                            Can we run some optimizations to remove the move before rejecting this code?

                    Can we have lifetimes which are related to the lifetime of an object?

                    Think of await <expr> as constructing the <expr> inplace

                    Can we have a PinnedGenerator which Generator maps to, only used inside combinators and await?

                Can we have pin() operation work for priming?
                    We'd need to have it call resume() for us. So it has to pass the resume argument.
                    It also may return some value

                Can we have generators use allocation to prevent them from moving?
                    See GeneratorsAllcation.txt

                Priming require us to duplicate poll() methods of future combinators?
                    Does this prevent optimizations? Possibly
                        Can the above feature help?

                        Can we write select() and join() as generators?

                        join(a, b) {
                            await a;
                            await b;
                        }

                        select(a, b) {

                        }

                        Hm.. select would need to prime both generators, but can also get the result of both!
                        It will a bit more logic.

                    Can we just prime all futures and then call poll on the result?



                With priming we'd need a way to get the argument without introducing a new suspend point

                How will priming work with a conditional suspend point?
                    We use the variables which are alive at the conditional suspend point

                Can we have futures were we only can prime() xor resume()? where prime() only works in the initial state.

                Have a default implementation for Prime and prime() on Futures/Generators

                Can https://github.com/rust-lang/rfcs/pull/1823 deal with priming due to the closures approach?
                    I don't think so

                We only really need to specify the lifetime bounds after awaiting, have some sugar for this?
                    Let => imply all the lifetimes of args are captured?

    http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0057r5.pdf
    https://isocpp.org/files/papers/N4402.pdf
    http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4453.pdf

    https://gist.github.com/jamboree/a2b3fe32eeb8c21e820c

How to deal with the memory used by a generator being revoked?

How can you yield from multiple generators in a row without duplicating the implicit argument?
    Require that the argument is copy?
    Then we'd need a way to access non-copy arguments
    Can we just let the argument copy if Copy and move otherwise?
    Will we need a way to reassign the hidden variable without a suspend point?
    If we want to call 2 yield froms in a row, we could clone the argument? Not possible!

    We can allow you to specify the argument to pass to yield from?

    Can we just use a for loop to simulate `yield form` and pass another argument to resume?

    Can we create another generator which just yields from the other and pass an argument to it?
        No, we'd need a for loop to do that.

    Can we have some sugar where await! gets the current argument and processes it before yielding from the next?
        Consider the case when the argument is Clone, but not Copy

        Say we're tracking the stack depth using some integer: Clone.

    Can we make yield from set the argument somehow?

    Does C++ allow you to pass an argument to resume()?

    We probably need a way to access the argument.
        When should the argument drop?

Does a representation where yield takes no arguments and resume() take no argument simplify things?
    Can we pass in an argument by some other mechanism?
        C++ has the concept of a promise, which allows you to alter internal state of the generator

Look at how LLVM optimizes coroutines
    If we inline LLVM style, we can apply optimizations for now known arguments

yield as generator for syntax?
or just yield from (also works)

Should we have magic for panics like C++ and Python?

How can C++ do await without a loop?
    It uses a callback based system

Python uses `async for` instead of `await for`

Can we later add support for futures using callbacks in Rust if we get non-movable types?

PROBLEM: We need to ban recursive generators. They result in recursive types. That is the generator frame contains itself.
    We also need to ban mutually recursive generators.
        We also can't allow this due to impl Trait?

Can we use yield from / await! as way to count stack frames / build a stack frame and other cool things?
    Use it to check stack overflow?
    Implement try! / ?  ?

When will the implicit argument be dropped?
    Can multiple of them be alive at once?
    So the lifetime of it cannot cross suspend points? Even in non-movable generators?
        That would be bad.
        Don't allow any way to borrow it? Just set/get?

    Can it live across await!?

    Only allow set and get of the implicit argument, no borrows
        Can we sneak in intrinsics here?
        take() to get the argument if it was not taken before?
        Could make a wrapper which specialized the behavior so that Some(arg) is always return if the argument is Copy
        set(value: Option<T>) would Drop the existing argument and use the provided one.
        yield also drops the existing argument.

        Provide stable take! and set! macros so users can use these
        #[allow_internal_unstable]

        Hm.. we'd need the type parameter of the intrinsics to match the argument type

        Can we have an implicit argument for all functions/closures? Which is initially None?

Alternative, non-movable types for generators
    See GeneratorsNonMovable.txt

Can we store the task "TLS" as a implicit argument?
    Probably required for callbacks, polling can store it in actual TLS

Optimization: If we pass constant values into a generator function. Can we duplicate the generate function and substitute in the constants. We replace the call with a call to the new function.
    Is there anything to gain by letting functions contain multiple nested generators like how LLVM allows?

Can we do some optimization where the body of a for loop is inserted as the yield statement of the generator?
    This does follow the same pattern as await!, loop resume()/next() until it returns Complete/None and we do something for every Yield(v)/Some(v).

    Say we have some loop that runs an freshly created generator to completion and handles every yield with some body of code. We can then inline the generator and replace yield statements inside with the body of code which handles it. This would apply to both await/`yield from` and for loops over iterators. This is kind of like 2-way inlining.

        To identify the body of code to put into the callee, we'd take the basic blocks that can lead back into the loop from the matched Yield.

        Since we'd have to duplicate the body of code inside the for loop, if it's expensive we'd like to avoid duplicating it.
            If the body contains no yield statements, we'd move the body out to a function and replace yields inside with a call.
                The inline could later inline it.
            If the body contains yield statements, we'd move the body out to a generator and replace the yields inside with an await on the generator. This optimization can later inline that.

    Too bad we can't change Iterator methods to use generators.

Optimization:
    We can inline resume(&mut self) where we only expand yield statments. We don't move variables into the generator frame.
    When inlining we connect up the variables with the variables in the local variable.

    So we first extract the required variables, before the resume() call, then store them back after.
        This creates more loads and stores though, might be a bad idea
        We can just require that the generator be a local variable, and expand it to it's variables.



    <eddyb> you can have desugared state switching but not desugared state
    <eddyb> if that makes sense
    <eddyb> that is, you do the state machine transform but not assign live variables to states
    <eddyb> then you inline
    <Zoxc> I'm not sure what you mean by assigning live variables to states
    <eddyb> Zoxc: a state contains a subset of the MIR locals
    <eddyb> live at that suspend point
    <Zoxc> How can you do the state machine transformation without doing that?
    <eddyb> Zoxc: you just keep referring to them as local variables
    <eddyb> i.e. you do the control-flow transform but no data-flow
    <CensoredUsername> Could someone with access add the relevant labels tot his tracking issue? https://github.com/rust-lang/rust/issues/36167
    <Zoxc> I don't see how that could work. Can you make an example of the control-flow-only transform and inlining on this code https://gist.github.com/Zoxc/d8dd9ce4cef23b5465bf7c0f5cce4c98 ?
    <Zoxc> eddyb: Probably should have an example with variables, but I don't see how you'd inline either so =P
    <eddyb> inline what?
    <eddyb> this isn't generator-generator inlining
    <Zoxc> eddyb: So if we have a generator created in this function which doesn't escape, we can replace it with it's variables and the state variable and use those directly when inlining resume()?

Can we have some optimization that overlaps the store of the RPC result inside the future and the result given to back to await?
    Would LLVM handle this well atm?

    The result might be in registers, so this can't always help

Would a callback model work well if we split up generators into a function for each suspend point?
    That is a bit messy with multiple threads, you'd need atomics ops to update the state?

    You can implement Join by just storing the result of the callbacks.

    We need to get the implicit argument and store it in a variable which lasts to return expressions.

    Select is a bit tricker. You'd want to pass through the first callback, but wait for a schedule on the second.
    How do you do select with non-movable futures? Poll has the same problem
        You can have a version of select which returns a borrow to the future that didn't complete yet.
            How can we write this?
        And you have have a version which boxes the futures and returns the future as a box.

    How can you create an future for an API which uses callbacks using polling futures?
        You can send a notification to the event loop that a future is ready. Which event loop? (The one which started the computation)

        Not very efficient

    How does cancellation compare with callbacks and polling?
        Cancellation would require cancelling RPCs, which are callback based.
        Since RPCs 

    What's the lifetime of the callback functions?
        fn schedule<'c, C: 'c>(callback: C<'c>) -> Future<'c> + ?Move

        Callback functions must outlive the future

        So use a pointer to the callback functor?
            fn schedule<'c, C: 'c'>(callback: &'c mut C) -> Future<'c> + ?Move

            How can we use this at the event loop level?
                We can have a 'static callback which just frees the Box containing the future?

        How can we write impl Future<'c>? We don't. That's only for the result of pin/schedule



    Can we panic in Drop if we don't allow cancellation?
        Does pancinking abort the destruction?

    Look at async streams with callbacks and interactions with yield

    Look at LLVM discussion for coroutines

    Can we send the resume point to the scheduler to avoid storing it in the generator frame?
        Is this slower? It avoids the need to separate save and suspend

    Callbacks calls the task that is waiting on it directly, polling requires a trip to the schedulers

    Callbacks wants tail call optimization when returning, so returning doesn't actually grow the stack
        This can lead to stack overflow issues overwise.

        Can we tail call even if we're supposed to free the future?

    Callbacks doesn't need to store the result of futures inside the future. We get it delivered.

    Polling require is to go deep inside tasks before finding the spot that is actually waiting on the event
        Inlining helps here
        Can we do something to improve this without inlining? Like a task instruction pointer? or a task suspend point?

    Conditional await can lead to code duplication if we let each suspend point be a function
        Do we need conditional await?

        What happens with suspend points inside loops?

    We can combine PinGenerator::pin() with schedule() to ensure we only schedule a callback once

    PROBLEM: How to deal with the resume() argument. Can it be implicit and pass around &mut EventLoop?

    Can we have a method on Future which runs before returning? And let impl Future for Generators with Return=!?
        Can we have InnerReturn and OuterReturn types, where resume() use outer types and the function body inner?
        How can the impl Trait provide the mapping here?

        impl<InnerReturn, T: Generator<fn () -> InnerReturn, Return=()>> Future for T {
            type Return = InnerReturn;
        }

        trait Generator<A: Abstraction<..?>> {

        }

        trait Abstraction<InnerReturn, InnerYield> {
            type OuterReturn = !;
            type OuterYield = !;
            fn map_return(inner: InnerReturn) -> OuterReturn;
        }

    Does callback work well for futures inside a kernel, driven by interrupts?
        Does Tock OS simulate a event loop using interrupts?
        Tock OS is syncronious though?

        Aren't interrupts fundematally sticky, which means they indicate readiness, not completeness?

        A CPU would schedule the driver task to run. When the driver runs, it will find the cause of the interrupt and then issue a callback.
            For the polling model, the driver would notify the scheduler that the future is ready to run. This corresponds to using a callback API with polling.

            Can we just poll the future directly in the driver? (since the driver is also ran by the scheduler)
                This is quite callback like
                    This is how the event loop in userspace would look
                Does futures-rs have something like this?
                This does bypass the scheduler
                Stack overflow dangers here

    Think about what nested generators with callback would work. A return is a callback there.